{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-processamento PLN",
      "provenance": [],
      "authorship_tag": "ABX9TyMawJW5ucl4est0uD5EP9Q5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguilarafa2010/PLN/blob/main/Pre_processamento_PLN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMu7suc3K0eC"
      },
      "source": [
        "# Contador de Palavras\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kODJRoY2Kxqo",
        "outputId": "24f0aa9b-8940-4274-ec93-ac297b8815cd"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "texto = 'Este texto está sendo utilizado para demonstrar o funcionamento de diferentes formas tokenização. O processo de tokenização pode ser realizado com objetivos distintos.'\n",
        "\n",
        "palavras = texto.replace('\\n',' ').replace('\\t','').replace(',', '').replace('.', ' ').split(' ')\n",
        "\n",
        "contador = Counter(palavras)\n",
        "                   \n",
        "for cont in contador.items():\n",
        "  print(cont)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Este', 1)\n",
            "('texto', 1)\n",
            "('está', 1)\n",
            "('sendo', 1)\n",
            "('utilizado', 1)\n",
            "('para', 1)\n",
            "('demonstrar', 1)\n",
            "('o', 1)\n",
            "('funcionamento', 1)\n",
            "('de', 2)\n",
            "('diferentes', 1)\n",
            "('formas', 1)\n",
            "('tokenização', 2)\n",
            "('', 2)\n",
            "('O', 1)\n",
            "('processo', 1)\n",
            "('pode', 1)\n",
            "('ser', 1)\n",
            "('realizado', 1)\n",
            "('com', 1)\n",
            "('objetivos', 1)\n",
            "('distintos', 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXchZiKbLri9"
      },
      "source": [
        "## Contador de Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-QxVGAgLrr4",
        "outputId": "edb490da-b2ad-4f95-fcaf-15975df5e1ec"
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk import tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "texto = 'Este texto está sendo utilizado para demonstrar o funcionamento de diferentes formas de tokenização. O processo de tokenização pode ser realizado com objetivos distintos.'\n",
        "palavras_tokenize = tokenize.word_tokenize(texto, language='portuguese')\n",
        "\n",
        "palavras_tokenize = [word.lower() for word in palavras_tokenize if word.isalpha()]\n",
        "\n",
        "print(palavras_tokenize)\n",
        "contador = Counter(palavras_tokenize)\n",
        "for cont in contador.items():\n",
        "  print(cont)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['este', 'texto', 'está', 'sendo', 'utilizado', 'para', 'demonstrar', 'o', 'funcionamento', 'de', 'diferentes', 'formas', 'de', 'tokenização', 'o', 'processo', 'de', 'tokenização', 'pode', 'ser', 'realizado', 'com', 'objetivos', 'distintos']\n",
            "('este', 1)\n",
            "('texto', 1)\n",
            "('está', 1)\n",
            "('sendo', 1)\n",
            "('utilizado', 1)\n",
            "('para', 1)\n",
            "('demonstrar', 1)\n",
            "('o', 2)\n",
            "('funcionamento', 1)\n",
            "('de', 3)\n",
            "('diferentes', 1)\n",
            "('formas', 1)\n",
            "('tokenização', 2)\n",
            "('processo', 1)\n",
            "('pode', 1)\n",
            "('ser', 1)\n",
            "('realizado', 1)\n",
            "('com', 1)\n",
            "('objetivos', 1)\n",
            "('distintos', 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysn2yto6PoEw"
      },
      "source": [
        "## Exemplo de Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3RTs4VlPnuv",
        "outputId": "e331b1dc-4281-4637-eba6-f4207817a04d"
      },
      "source": [
        "nltk.download('rslp')\n",
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "print(stemmer.stem(\"abóbora\"))\n",
        "print(stemmer.stem(\"maça\"))\n",
        "print(stemmer.stem(\"Curitiba\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n",
            "abób\n",
            "maç\n",
            "curitib\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}